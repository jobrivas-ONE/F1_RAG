import streamlit as st
import os
from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI
from langchain_community.vectorstores import Chroma
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
from PIL import Image
__import__('pysqlite3')
import sys
sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')


from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI
# ... (el resto de tus imports) ...

# --- IMPORTANTE: Configura tu clave de API aqu√≠ si ejecutas localmente sin Streamlit Cloud secrets ---
# En Streamlit Cloud, la API Key debe gestionarse v√≠a st.secrets (configuraci√≥n avanzada)
# Si lo ejecutas localmente, puedes descomentar la l√≠nea de abajo y poner tu clave.
# os.environ["GOOGLE_API_KEY"] = "TU_API_KEY_AQUI" 

# --- Credenciales de Autenticaci√≥n para el prototipo ---
# En un entorno de producci√≥n, esto deber√≠a gestionarse de forma m√°s segura (ej. st.secrets, bases de datos)
USERNAME = "muriel.espinosa"
PASSWORD = "MurEsp2017..??" # !!! CAMBIAR ESTO POR UN VALOR M√ÅS FUERTE Y SEGURO !!!

# --- Configuraci√≥n de la p√°gina de Streamlit ---
st.set_page_config(page_title="Asistente Acad√©mico de Ingenier√≠a", page_icon="üéì", layout="wide")

# --- Funci√≥n de Autenticaci√≥n ---
def check_password():
    """Returns `True` if the user's password is correct, `False` otherwise."""

    # Inicializar el estado de autenticaci√≥n si no existe
    if "password_correct" not in st.session_state:
        st.session_state["password_correct"] = False
    
    if st.session_state["password_correct"]:
        return True # Ya autenticado

    # Mostrar formulario de login si no est√° autenticado
    st.sidebar.title("Acceso al Asistente")
    with st.sidebar.form("login_form"):
        st.text_input("Usuario", key="username_input")
        st.text_input("Contrase√±a", type="password", key="password_input")
        submitted = st.form_submit_button("Entrar")

        if submitted:
            if (st.session_state.username_input == USERNAME and 
                st.session_state.password_input == PASSWORD):
                st.session_state["password_correct"] = True
                st.success("¬°Acceso concedido! Recargando...")
                st.rerun() # Forzar un rerun para ocultar el login
            else:
                st.error("üòï Usuario o contrase√±a incorrectos")
        return False

# --- Inclusi√≥n de Logos en el Encabezado ---
col1, col2 = st.columns([1, 5]) # Ajusta la proporci√≥n de las columnas para los logos y el t√≠tulo

with col1:
    try:
        logo_uoh = Image.open("logo_uoh.png")
        st.image(logo_uoh, width=100) # Ajusta el ancho seg√∫n sea necesario
    except FileNotFoundError:
        st.error("Logo UOH no encontrado. Aseg√∫rate de que 'logo_uoh.png' est√© en la carpeta.")
    
    try:
        logo_eIng = Image.open("logo_eIng.png")
        st.image(logo_eIng, width=100) # Ajusta el ancho seg√∫n sea necesario
    except FileNotFoundError:
        st.error("Logo E.Ing no encontrado. Aseg√∫rate de que 'logo_eIng.png' est√© en la carpeta.")

with col2:
    st.title("üéì Asistente Acad√©mico IA de Ingenier√≠a")
st.write("Bienvenido/a. Soy tu asistente para consultar patrones y tendencias de los datos agregados de estudiantes.")


@st.cache_resource
def cargar_recursos():
    """
    Carga los recursos pesados (modelo, DB) una sola vez para que la app sea r√°pida.
    """
    if not os.path.exists("chroma_db"):
        st.error("¬°La base de datos 'chroma_db' no ha sido creada! Por favor, ejecuta primero el script 'preparar_base_de_datos.py'.")
        return None

    st.info("Cargando base de datos y modelo... Por favor, espera.")
    
    # Comprobamos la API Key antes de cargar los embeddings
    if not os.environ.get("GOOGLE_API_KEY"):
        st.error("Error: GOOGLE_API_KEY no configurada. No se pueden cargar los modelos.")
        return None

    embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001")
    vector_store = Chroma(persist_directory="chroma_db", embedding_function=embeddings)
    llm = ChatGoogleGenerativeAI(model="gemini-1.0-pro", temperature=0.2, convert_system_message_to_human=True)
    retriever = vector_store.as_retriever(search_kwargs={'k': 5}) # Recupera 5 documentos m√°s relevantes
    
    template = """
    Eres un asistente acad√©mico experto en analizar datos de estudiantes. Tu objetivo en esta FASE 1 es brindar insights sobre **patrones, tendencias y perfiles cualitativos a nivel agregado**. NO debes responder preguntas sobre datos espec√≠ficos de un solo estudiante (ej. RUT, nombre, historial individual).

    Usa la siguiente informaci√≥n de contexto para responder la pregunta de manera precisa y concisa, siempre enfoc√°ndote en las tendencias generales.
    El contexto se compone de fichas de estudiantes desidentificadas. Anal√≠zalas para identificar patrones.
    Si la informaci√≥n para identificar un patr√≥n no est√° en el contexto, indica que no tienes datos suficientes. No inventes respuestas.
    Organiza tu respuesta de forma clara y f√°cil de leer.

    Contexto:
    {context}

    Pregunta:
    {question}

    Respuesta √∫til:
    """
    prompt = PromptTemplate(template=template, input_variables=["context", "question"])
    
    qa_chain = RetrievalQA.from_chain_type(
        llm=llm,
        chain_type="stuff",
        retriever=retriever,
        return_source_documents=True,
        chain_type_kwargs={"prompt": prompt}
    )
    st.success("¬°Recursos cargados! Ya puedes hacer tus preguntas sobre patrones.")
    return qa_chain

# --- L√≥gica principal de la aplicaci√≥n, protegida por la autenticaci√≥n ---
if not check_password():
    st.stop() # Detiene la ejecuci√≥n si el usuario no est√° autenticado

# --- Si la autenticaci√≥n es exitosa, el resto del c√≥digo se ejecuta ---
if not os.environ.get("GOOGLE_API_KEY"): # Doble chequeo por si no se carg√≥ por Streamlit Cloud o local
    st.warning("üö® ¬°ALERTA! La GOOGLE_API_KEY no est√° configurada. La aplicaci√≥n no funcionar√° correctamente.")
else:
    chain = cargar_recursos()

    if chain:
        # Inicializamos las variables en el estado de la sesi√≥n si no existen
        if 'pregunta_usuario' not in st.session_state:
            st.session_state.pregunta_usuario = ""
        if 'respuesta' not in st.session_state:
            st.session_state.respuesta = None
        if 'fuentes' not in st.session_state:
            st.session_state.fuentes = None
        
        with st.form(key='query_form'):
            pregunta_actual = st.text_area(
                "Escribe tu pregunta aqu√≠ (enfocada en patrones o tendencias):",
                value=st.session_state.pregunta_usuario,
                height=150, 
                placeholder="Ej: Describe los factores comunes en los estudiantes con alto rendimiento en el primer a√±o."
            )
            submit_button = st.form_submit_button(label='Generar Respuesta üöÄ')

        if submit_button:
            st.session_state.pregunta_usuario = pregunta_actual # Guardar la pregunta en sesi√≥n

            # --- L√≥gica de FASE 1: Limitar a preguntas sobre patrones/tendencias, rechazando preguntas individuales ---
            # Palabras clave que sugieren una pregunta sobre un estudiante espec√≠fico
            pregunta_individual_keywords = ["rut", "id de estudiante", "nombre", "historial de", "situaci√≥n de", "perfil de", "dame la info de"]
            es_pregunta_individual = any(keyword in pregunta_actual.lower() for keyword in pregunta_individual_keywords)

            if es_pregunta_individual:
                st.session_state.respuesta = (
                    "**Respuesta del Sistema (Fase 1):**\n\n"
                    "En esta Fase 1, el asistente est√° dise√±ado para brindar informaci√≥n sobre **tendencias y patrones agregados**. "
                    "Las consultas sobre datos espec√≠ficos de un estudiante individual (ej. usando RUT, nombre o ID) "
                    "no est√°n habilitadas para garantizar la privacidad y se implementar√°n en fases futuras "
                    "con estrictos controles de acceso."
                )
                st.session_state.fuentes = [] # No hay fuentes para este tipo de respuesta de pol√≠tica
            elif not pregunta_actual: # Manejar el caso de una pregunta vac√≠a
                st.warning("Por favor, ingresa una pregunta para generar una respuesta.")
                st.session_state.respuesta = None
                st.session_state.fuentes = None
            else: # Si la pregunta NO es individual y no est√° vac√≠a, intentamos procesarla con RAG (para patrones agregados)
                with st.spinner("Buscando en los archivos desidentificados y generando una respuesta... üß†"):
                    try:
                        resultado = chain.invoke({"query": st.session_state.pregunta_usuario}) 
                        st.session_state.respuesta = resultado["result"]
                        st.session_state.fuentes = resultado["source_documents"]
                    except Exception as e:
                        st.error(f"Ocurri√≥ un error al contactar la API. Revisa tu clave de API y la conexi√≥n a internet. Error: {e}")
                        st.session_state.respuesta = None
                        st.session_state.fuentes = None

        # Mostramos la respuesta si existe en el estado de la sesi√≥n
        if st.session_state.respuesta:
            st.write("### Respuesta a tu consulta:")
            st.info(st.session_state.respuesta)
            
            with st.expander("Ver fuentes de datos consultadas (Fichas desidentificadas)"):
                if st.session_state.fuentes: # Solo iterar si hay fuentes
                    for doc in st.session_state.fuentes:
                        st.write("---")
                        st.write(doc.page_content)
                else:
                    st.write("No hay fuentes de datos directas para esta respuesta (respuesta de pol√≠tica de la Fase 1).")