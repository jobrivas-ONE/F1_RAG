import streamlit as st
import os
import io
import pandas as pd
from PIL import Image
import re # <-- AÃ±adir esta importaciÃ³n para expresiones regulares

# --- SOLUCIÃ“N TEMPORAL PARA COMPATIBILIDAD DE SQLITE3 EN STREAMLIT CLOUD (SI ES NECESARIO) ---
# Si el error "sqlite3.OperationalError" persiste, intenta descomentar las siguientes dos lÃ­neas.
# Sin embargo, con "pysqlite3-binary" y la inicializaciÃ³n explÃ­cita, a menudo no son necesarias.
# __import__('pysqlite3')
# import sys
# sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')
# ------------------------------------------------------------------------------------------

from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI
from langchain_community.vectorstores import Chroma
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate

# --- CONFIGURACIÃ“N DE PÃGINA ---
st.set_page_config(
    page_title="Asistente de InformaciÃ³n de Estudiantes - UOH",
    page_icon="ðŸŽ“",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- FunciÃ³n para detectar RUTs (NUEVA FUNCIÃ“N) ---
def contains_rut(text):
    # ExpresiÃ³n regular para detectar RUTs chilenos (XX.XXX.XXX-X o X.XXX.XXX-X)
    # Permite puntos opcionales y guion.
    rut_pattern = r'\b\d{1,2}\.\d{3}\.\d{3}[-][0-9kK]\b|\b\d{7,8}[-][0-9kK]\b'
    return re.search(rut_pattern, text) is not None

# --- AutenticaciÃ³n (con correcciÃ³n de st.experimental_rerun a st.rerun) ---
def check_password():
    """Returns `True` if the user's password is correct, `False` otherwise."""

    if "password_correct" not in st.session_state:
        st.session_state["password_correct"] = False
    
    if st.session_state["password_correct"]:
        return True # Ya autenticado

    # Mostrar formulario de login si no estÃ¡ autenticado
    st.sidebar.title("Acceso al Asistente")
    with st.sidebar.form("login_form"):
        st.text_input("Usuario", key="username_input")
        st.text_input("ContraseÃ±a", type="password", key="password_input")
        submitted = st.form_submit_button("Entrar")

        if submitted:
            # Leer credenciales desde st.secrets si estÃ¡n configuradas
            if "USERNAME" in st.secrets and "PASSWORD" in st.secrets:
                USERNAME = st.secrets["USERNAME"]
                PASSWORD = st.secrets["PASSWORD"]
            else:
                # Fallback a credenciales hardcodeadas (Â¡CAMBIAR ESTO EN PRODUCCIÃ“N!)
                USERNAME = "usuario_sochedi"
                PASSWORD = "password_seguro_y_largo" # <--- Â¡CAMBIA ESTO!

            if (st.session_state.username_input == USERNAME and 
                st.session_state.password_input == PASSWORD):
                st.session_state["password_correct"] = True
                st.success("Â¡Acceso concedido! Recargando...")
                st.rerun() # <-- CORRECCIÃ“N AQUÃ
            else:
                st.error("ðŸ˜• Usuario o contraseÃ±a incorrectos")
        return False

# --- Cargar recursos (LLM y Vector Store) ---
@st.cache_resource
def cargar_recursos():
    # Cargar la GOOGLE_API_KEY desde los secretos de Streamlit Cloud
    if "GOOGLE_API_KEY" not in st.secrets:
        st.error("ðŸš¨ La clave GOOGLE_API_KEY no estÃ¡ configurada en los secretos de Streamlit.")
        st.stop()
    os.environ["GOOGLE_API_KEY"] = st.secrets["GOOGLE_API_KEY"]

    # Inicializar el modelo de Embeddings
    embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001")

    # Inicializar el modelo de lenguaje (LLM)
    llm = ChatGoogleGenerativeAI(model="gemini-1.0-pro", temperature=0.2, convert_system_message_to_human=True) # <-- MODELO ESTABLE

    # Inicializar ChromaDB (con cliente persistente explÃ­cito)
    from chromadb import PersistentClient
    try:
        # Intenta cargar el cliente de persistencia
        client = PersistentClient(path="chroma_db")
        # AsegÃºrate de que el collection_name coincida con el que usaste en preparar_base_de_datos.py
        # Si no especificaste uno, el valor por defecto de LangChain suele ser "langchain"
        vector_store = Chroma(
            client=client,
            collection_name="langchain", # O el nombre que usaste si lo especificaste
            embedding_function=embeddings
        )
        st.sidebar.success("âœ… Base de conocimiento cargada.")
    except Exception as e:
        st.error(f"âŒ Error al cargar ChromaDB: {e}. AsegÃºrate que la carpeta 'chroma_db' estÃ¡ completa y no estÃ¡ corrupta.")
        st.stop() # Detener la ejecuciÃ³n si falla la carga
        return None # Devuelve None si falla la carga

    # Plantilla de Prompt (adaptada para un asistente acadÃ©mico)
    template = """Eres un asistente virtual de la Escuela de IngenierÃ­a UOH.
    Tu objetivo es ayudar a los usuarios a obtener informaciÃ³n SOBRE DATOS AGREGADOS DE LOS ESTUDIANTES.
    NO PUEDES PROPORCIONAR INFORMACIÃ“N INDIVIDUALIZADA O PERSONAL DE NINGÃšN ESTUDIANTE.
    Responde las preguntas del usuario basÃ¡ndote Ãºnicamente en el siguiente contexto:
    {context}
    Si la pregunta no se puede responder con la informaciÃ³n proporcionada en el contexto, simplemente di que no tienes suficiente informaciÃ³n para responder.
    No intentes inventar una respuesta.
    MantÃ©n tus respuestas claras, concisas y en espaÃ±ol.

    Pregunta del usuario: {question}
    Respuesta:"""
    QA_CHAIN_PROMPT = PromptTemplate.from_template(template)

    # Crear la cadena de RetrievalQA
    chain = RetrievalQA.from_chain_type(
        llm,
        retriever=vector_store.as_retriever(search_kwargs={"k": 3}), # Busca los 3 documentos mÃ¡s relevantes
        chain_type_kwargs={"prompt": QA_CHAIN_PROMPT},
        return_source_documents=True
    )
    return chain

# --- LÃ³gica principal de la aplicaciÃ³n ---
def main():
    if not check_password():
        st.stop() # Detener la ejecuciÃ³n si no estÃ¡ autenticado

    # Cargar y mostrar logos
    col1, col2, col3 = st.columns([1, 4, 1])
    with col1:
        st.image(Image.open(io.BytesIO(open("logo_uoh.png", "rb").read())), width=80)
    with col2:
        st.title("Asistente de InformaciÃ³n de Estudiantes")
        st.markdown("##### Escuela de IngenierÃ­a UOH")
    with col3:
        st.image(Image.open(io.BytesIO(open("logo_eIng.png", "rb").read())), width=80)

    st.markdown("---")
    st.write("Â¡Hola! Soy tu asistente virtual. Puedes preguntarme sobre el desempeÃ±o acadÃ©mico de los estudiantes de la UOH.")
    st.write("Por ejemplo: 'Â¿CuÃ¡l es el PPA promedio de los estudiantes de IngenierÃ­a Civil?' o 'Â¿CuÃ¡ntos estudiantes reprobaron CÃ¡lculo I el semestre pasado?'")
    st.write("**âš ï¸ Importante:** Por motivos de privacidad, no puedo responder preguntas sobre informaciÃ³n personal o datos individualizados de estudiantes especÃ­ficos (como su RUT, nombre o calificaciones personales).")


    # BotÃ³n para limpiar cachÃ© y recargar la aplicaciÃ³n (Ãºtil para depuraciÃ³n)
    if st.button("ðŸ”„ Limpiar cachÃ© y Recargar la App"):
        st.cache_data.clear()
        st.cache_resource.clear()
        st.rerun()

    # Cargar recursos (LLM y Vector Store)
    chain = cargar_recursos()

    if chain is None:
        st.error("No se pudo inicializar el asistente. Por favor, revisa los logs.")
        st.stop()

    # Inicializar historial de chat
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # Mostrar mensajes del historial
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # Entrada de usuario
    if prompt := st.chat_input("Â¿En quÃ© puedo ayudarte?"):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        with st.chat_message("assistant"):
            with st.spinner("Buscando y generando respuesta..."):
                # --- LÃ“GICA DE PRIVACIDAD AÃ‘ADIDA AQUÃ ---
                if contains_rut(prompt) or "personal" in prompt.lower() or "individual" in prompt.lower() or "nombre" in prompt.lower():
                    response_text = "Lo siento, como asistente de la UOH, no puedo proporcionar informaciÃ³n personal o individualizada de los estudiantes por razones de privacidad. Solo puedo responder preguntas sobre datos agregados."
                    st.markdown(response_text)
                    st.session_state.messages.append({"role": "assistant", "content": response_text})
                else:
                    # Si no es una pregunta de privacidad, procede con el RAG normal
                    response = chain.invoke(prompt)
                    st.markdown(response["result"])
                    st.session_state.messages.append({"role": "assistant", "content": response["result"]})

                    # Opcional: Mostrar documentos fuente para depuraciÃ³n (descomentar si es necesario)
                    with st.expander("Ver documentos fuente"):
                        if response["source_documents"]:
                            for doc in response["source_documents"]:
                                st.write(doc.page_content)
                                st.write(f"Metadata: {doc.metadata}")
                        else:
                            st.write("No se encontraron documentos relevantes.")
                # ----------------------------------------

if __name__ == "__main__":
    # Asegurarse de que el directorio 'chroma_db' exista para que PersistentClient no falle al inicio.
    if not os.path.exists("chroma_db"):
        st.warning("La carpeta 'chroma_db' no se encontrÃ³. AsegÃºrate de que estÃ¡ en el mismo directorio que app.py.")
        # st.stop() # Si la ausencia de la DB debe ser un error fatal, descomentar
        
    main()